{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c4c6d61cdeab003",
   "metadata": {},
   "source": [
    "# 层和块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "887e20c36671e92f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T09:00:15.062134Z",
     "start_time": "2024-12-01T09:00:12.761688Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2a55cc91b903bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(20, 256),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(256,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54c04182-72eb-4bf9-bfbc-98162e3bf8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(2, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc39ebeb-aa54-4a8f-98a2-699f383e8457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1618, -0.0901, -0.1610,  0.1158,  0.1683,  0.0073, -0.1686, -0.0007,\n",
       "         -0.0976, -0.2782],\n",
       "        [ 0.2203, -0.0321, -0.3254, -0.0316,  0.3107, -0.0478, -0.1845,  0.0938,\n",
       "          0.0011, -0.3159]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c82c4fe-4fde-4497-8ab6-dccdb457556d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1814, -0.0706, -0.2040,  0.0268,  0.2581, -0.0777, -0.1023,  0.0570,\n",
       "         0.0465, -0.2824], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_no_batch = torch.rand(20)\n",
    "net(X_no_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cef543-8769-4057-8eaf-4d70b36caf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d499953-c06f-403d-b550-67a4ebfffbe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c30ce4c9-2fa6-4802-b56a-f841ddf3e67e",
   "metadata": {},
   "source": [
    "# 自定义块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75acf91d-fe56-43a7-98f1-45b2ffeaebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "nn.Moudle 继承了一些很好用的类\n",
    "\n",
    "所有的moudle有两个比较好用的函数，\n",
    "一个是__init__,在里面定义哪些类和参数\n",
    "\n",
    "\"\"\"\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # 调用父类的，就是nn.Moudle，把一些内部所需要的参数全部设置好，初始化weight啊全部弄好\n",
    "        # 定义两个隐藏层\n",
    "        self.hidden = nn.Linear(20, 256) # 存在类的成员变量里面\n",
    "        self.out = nn.Linear(256, 10) # 存在类的成员变量里面，名字就随便怎么定义了\n",
    "\n",
    "    def forward(self, X): # self 就是python编程指向自己的那个东西 输入是我们的X\n",
    "        return self.out(F.relu(self.hidden(X))) # F 里面实现了大量的常用的一些函数 ，做了激活后 到out里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fec8f13b-2c30-4a1e-a627-19333a28a65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0698,  0.1312, -0.0775,  0.1454,  0.0396,  0.0869, -0.1455, -0.0200,\n",
       "          0.0820,  0.0556],\n",
       "        [-0.0028,  0.1275,  0.0091,  0.2196,  0.2538, -0.0036, -0.3570, -0.1665,\n",
       "         -0.0899,  0.3254]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7410e67e-9830-48a1-937b-b2611d6a0dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 20])\n",
      "torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(net(X).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79e5edb3-b585-4478-9c0c-f88df5c2d9c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.7178e-04, -1.5767e-01,  3.8272e-01, -1.8283e-01, -2.0700e-02,\n",
       "         7.6819e-02, -3.1900e-01,  5.1230e-02,  4.1515e-02,  4.8142e-02],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(X_no_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a26f4e9-71d1-46ad-8e5e-d335203376f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(X_no_batch.shape)\n",
    "print(net(X_no_batch).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09d390f-aa73-487c-b2d1-261f0a4b5def",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1547b528-9afe-4a38-9fa7-dc499f5d98dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e224c20f-25ea-4a88-8801-25c709150a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "681903b5-6c07-46a9-84a5-43faf3457d71",
   "metadata": {},
   "source": [
    "# 顺序块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f728289e-3518-41ab-9bad-17a0b9e85714",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "自己实现 经常使用的 nn.sequential()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "100ebc55-fc33-4f10-b715-68e5d546d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args): # 这里不一样，多接受了一个 list of input arguments\n",
    "        super().__init__()\n",
    "        for block in args: # 这个好理解吧， 就是我们平常输入的那样，很多个层\n",
    "            self._modules[block] = block # 然后放到一个特殊的成员变量里，一个特殊的容器，pytorch就会知道放在里面都是我需要的一些特殊的层\n",
    "                                        # 就是一个Orderdictionary,按顺序的字典 ， 所以排列的顺序就和插入进去是一样的\n",
    "    def forward(self, X):\n",
    "        for block in self._modules.values():\n",
    "            X = block(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88d5a8ab-c87b-4678-a2c6-ed6f1854c0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0565, -0.0323,  0.1675, -0.0619,  0.0326,  0.1844, -0.0448, -0.0229,\n",
       "         -0.1054, -0.0008],\n",
       "        [ 0.0573,  0.0516,  0.2720, -0.0485, -0.0695,  0.2480, -0.0728,  0.0652,\n",
       "         -0.0382,  0.0541]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "net(X)\n",
    "# 哈哈哈自己实现了一个seq... 太酷啦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e95f0e-915a-423b-bef8-eed3a07bcb79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a51a58-d116-4a28-bab8-e4af59b0709b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35570579-d2b1-4dd6-a03e-3c3390934af6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0443fa13-097a-41e3-a9cd-25b71d159d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82675bb0-fe50-40d4-b50b-943af16c2311",
   "metadata": {},
   "source": [
    "# 在正向传播中执行代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc6d42cb-5d46-4c64-82b7-e3a74946d2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"好处是当sequential满足不了自己的需求的时候，可以方便的自定义'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"好处是当sequential满足不了自己的需求的时候，可以方便的自定义\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccbad087-a978-4751-b038-4995df873f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.2287, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FixedHiddenMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rand_weight = torch.rand((20,20), requires_grad=False)\n",
    "        self.linear = nn.Linear(20, 20)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.linear(X)\n",
    "        X = F.relu(torch.mm(X, self.rand_weight) + 1)\n",
    "        X = self.linear(X)\n",
    "        while X.abs().sum() > 1:\n",
    "            X /= 2\n",
    "        return X.sum()\n",
    "net = FixedHiddenMLP()\n",
    "net(X)\n",
    "\n",
    "# 通过从继承nn.Module 可以灵活地"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f76329-00dd-440c-8d01-05cb9ef699ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e4f294-656d-4419-9d0f-c8d07b041bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5475fef9-a264-4450-acb3-fb0072fafb80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de3cdaac-0268-458a-a37a-80301af8f24c",
   "metadata": {},
   "source": [
    "# 混合搭配各种组合快的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62a34f8c-2bcb-46f1-afa7-59a66de7d55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2992, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NestMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(20, 64), nn.ReLU(),\n",
    "                                 nn.Linear(64, 32), nn.ReLU())\n",
    "        self.linear = nn.Linear(32, 16)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.linear(self.net(X)) # 疯狂套娃\n",
    "\n",
    "chimera = nn.Sequential(NestMLP(), nn.Linear(16,20), FixedHiddenMLP()) # 疯狂疯狂套娃\n",
    "chimera(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab5d97c-e88f-49c8-9b6b-4d22f4c3faaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"虽然比sequentiall麻烦一点，但是可以灵活组合各种块，（论文代码都是这样的，所以已经习惯了，反而是sequential见不到哈哈哈）\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323e0524-7205-465f-ab54-d57acd1f5dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
